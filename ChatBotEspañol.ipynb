{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBotEspañol.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdN_3uEpTfwf"
      },
      "source": [
        "#ChatBot en Español \n",
        "Con **\"Soft-Attention\"** de Bahdanau: https://arxiv.org/pdf/1409.0473.pdf\n",
        "\n",
        "Autor: Mario Xavier Canche Uc, mario.canche@cimat.mx\n",
        "\n",
        "Basado en: https://medium.com/@ruben_onelove/como-hacer-un-chatbot-en-espa%C3%B1ol-y-que-te-trolee-en-el-intento-2a8105d66de8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE4schF8T1al"
      },
      "source": [
        "## Montamos la carpeta del proyecto en Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og7poCKdUHOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db6b75f5-42a0-400d-9afb-18bcbfd4be2e"
      },
      "source": [
        "# Montamos el Drive al Notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvoB-Rg9UHRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65aafba6-17ef-4e2e-d0e2-7e079bcc9525"
      },
      "source": [
        "# Verificamos el directorio en el que nos encontramos\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9ZpV3k_UHUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d746fb8-55e2-4afa-8b37-47a5f2b361d4"
      },
      "source": [
        "# Cambiamos de directorio al Drive\n",
        "import os\n",
        "os.chdir(\"drive/My Drive/Tarea02_MarioXavierCancheUc/chatbot\")\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t\t\t\t\t  pre_processing.py  settings.py\n",
            "MarioXavierCancheUc_ChatBotEspañol.ipynb  __pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2KS-EUDD8hT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qWNNu6nD8wf"
      },
      "source": [
        "# Descargamos el DataSet\n",
        "##! pip install wget\n",
        "\n",
        "##import wget\n",
        "\n",
        "##url = \"http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2018/mono/OpenSubtitles.raw.es.gz\"\n",
        "\n",
        "##print(\"Descargando dataset...\")\n",
        "##wget.download(url, 'data/OpenSubtitles.raw.es.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxa2ip9TPyIT"
      },
      "source": [
        "# Descomprimimos el archivo descargado\n",
        "##import gzip\n",
        "##import shutil\n",
        "##with gzip.open('data/OpenSubtitles.raw.es.gz', 'rb') as f_in:\n",
        "##    with open('data/es.txt', 'wb') as f_out:\n",
        "##        shutil.copyfileobj(f_in, f_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSJ0d5wDYJky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ae8119-0c61-40e5-8a00-3028d1cc78a5"
      },
      "source": [
        "# Verificamos que se descomprimiera correctamente\n",
        "!head data/es.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NETKonet trae para ti...\n",
            "\"Twenty\"\n",
            "[NEW Presenta]\n",
            "[Una producción de A M Tree Pictures]\n",
            "[Sidus HQ]\n",
            "[Productor ejecutivo:\n",
            "Kim Woo Taek]\n",
            "Somos los típicos amigos de la secundaria que juraron que su amistad duraría para siempre.\n",
            "Aunque las circunstancias del inicio de nuestra amistad no fueron especiales en cierto modo fueron especiales para nosotros.\n",
            "Ejem... ejem.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLwtC3rwMo2T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwEMWSN1VVSH"
      },
      "source": [
        "## Preprocesamos los Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DUcKbjXTgK7"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random, itertools, pickle\n",
        "from settings import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjqTO-dfVPOh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d66cc16d-4674-4e09-e7a8-22e9c22b1177"
      },
      "source": [
        "#resumen del proceso\n",
        "#1 cargar todas diccionario con line index y sentence\n",
        "#2 elminiar las mas largas de 50\n",
        "#3 añadir las palabras al vocabulario\n",
        "#4 eliminar las sentence con palabras que no salen\n",
        "#5 pasar los pares con line index contiguos\n",
        "\n",
        "# n_lines = 0\n",
        "# n_tokens = 0\n",
        "# with open(corpus, 'rb') as file:\n",
        "#     for line in file:\n",
        "#         n_lines += 1\n",
        "#         n_tokens += len(line)\n",
        "\n",
        "n_lines = 213_517_354\n",
        "f\"Lineas usadas sobre el total:{LINES_USED/n_lines:.3%}\"\n",
        "\n",
        "# n_words = 0\n",
        "# with open(corpus, 'rb') as file:\n",
        "#     for line in file:\n",
        "#         n_words += len(line)\n",
        "# print(f'Numero de tokens: {n_words}')\n",
        "n_words= 6_836_670_604\n",
        "f\"Number of tokens: {n_words}\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Number of tokens: 6836670604'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3XGdb1sVPRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd5eef4-80e6-4a30-ee8b-c0c3c5f801c0"
      },
      "source": [
        "def printLines(how_many=10, start=0, decode=False):\n",
        "    with open(corpus, 'rb') as datafile:\n",
        "        for i,line in enumerate(datafile):\n",
        "            if i < start: continue\n",
        "            if decode:\n",
        "                print(i,line.decode(\"utf-8\"))\n",
        "            else:\n",
        "                print(i,line)\n",
        "            if i==start+how_many: break\n",
        "\n",
        "# printLines(1000,700_000,decode=True)\n",
        "\n",
        "#funcion para buscar ejemplos a la hora de tratar la puntuacion\n",
        "def search_line(search_string,stop=10):\n",
        "    n=0\n",
        "    prev_line,line_found = \"\",\"\"\n",
        "    prnt = False\n",
        "    \n",
        "    with open(corpus, 'rb') as datafile:\n",
        "        for i,line in enumerate(datafile):\n",
        "            if prnt:\n",
        "                print(f\"------Línea {i-1}------\")\n",
        "                print(prev_line.decode(\"utf-8\"),line_found.decode(\"utf-8\"),\n",
        "                      line.decode(\"utf-8\"), sep=\"\\n\")\n",
        "                prnt = False\n",
        "                n+=1\n",
        "                if n==stop:\n",
        "                    break\n",
        "            if search_string in line: \n",
        "                line_found = line\n",
        "                prnt = True\n",
        "            else:\n",
        "                prev_line = line\n",
        "                \n",
        "# search_line(b\"[\",100)\n",
        "\n",
        "#Procesado de la puntuación\n",
        "def process_punct(s):#complejo\n",
        "    s = s.strip().lower().decode()\n",
        "    s = re.sub(r\"\\.000\",r\" mil\", s)\n",
        "    s = re.sub(r\"^-\",       r\"<GUION_INIC>\", s)\n",
        "    s = re.sub(r\"-{2}\",     r\"<GUION_DOBL>\", s)\n",
        "    s = re.sub(r\"\\.{3}\",    r\"<TRIP_DOT>\", s)\n",
        "    s = re.sub(r\"{y:bi}\",   r\"<SPECIAL_1>\", s)\n",
        "    s = re.sub(r\"(\\w)-(\\w)\",r\"\\1<GUION_INTER>\\2\", s)\n",
        "    s = re.sub(r\"([\\):!?])\",r\" \\1\", s)      #separa puntuacion con espacio antes\n",
        "    s = re.sub(r\"([\\(¡¿])\", r\"\\1 \", s)      #separa puntuacion con espacio despues\n",
        "    s = re.sub(r\"([\\\"-,¿\\.}])\", r\" \\1 \", s) #espacio antes y despues\n",
        "    \n",
        "    #separa los tokens\n",
        "    s = re.sub(r\"<\", r\" <\", s)\n",
        "    s = re.sub(r\">\", r\"> \", s)\n",
        "    \n",
        "    s = re.sub(r\"\\s<GUION_INTER>\\s\",r\"-\", s)\n",
        "    return s\n",
        "\n",
        "import unicodedata\n",
        "def process_punct(s): #simple #punct2\n",
        "    s = s.strip().lower().decode()\n",
        "    s = re.sub(r\"^-\",       r\"<GUION_INIC>\", s)\n",
        "    s = re.sub(r\"\\.{3}\",    r\"<TRIP_DOT>\", s)\n",
        "    s = re.sub(r\"{y:bi}\",   r\"<TKN_A>\", s)\n",
        "    s = ''.join((c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c) != 'Mn')) #quita tildes\n",
        "    s = re.sub(r\"([.¡!¿?])\", r\" \\1 \", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.¡!¿?<>_\\d]+\", r\" \", s)\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    \n",
        "    s = re.sub(r\"<\", r\" <\", s)\n",
        "    s = re.sub(r\">\", r\"> \", s)\n",
        "    return s\n",
        "\n",
        "def process_punct(l):\n",
        "    s = l.lstrip(b\"-\").strip().lower().decode()\n",
        "    s = re.sub(r'\"', r\"\", s) \n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)           #separa puntuacion\n",
        "    s = re.sub(r\"([.¡¿])\", r\"\\1 \", s)           #separa puntuacion\n",
        "    s = re.sub(r\"[,]\",r\"\",s)                    #quita las comas\n",
        "    return s\n",
        "\n",
        "def loadLines(file, total_lines=10, max_lenght=MAX_LENGTH):\n",
        "    with open(file, 'rb') as datafile:\n",
        "        n=0\n",
        "        for i,line in enumerate(datafile):\n",
        "            if max(line.find(b\"[\"),line.find(b\"]\")) == -1: #filtra los comentarios\n",
        "                s = process_punct(line)\n",
        "                s = s.strip().split()\n",
        "                if len(s) < max_lenght: #filtra frases largas\n",
        "                    n+=1\n",
        "                    yield i,s\n",
        "            if n==total_lines: break\n",
        "                \n",
        "# for i,l in loadLines(corpus,10): print(i,l)\n",
        "\n",
        "print(\"#Test  0:\", process_punct(\"-t. -t\".encode()))\n",
        "print(\"#Test  1:\", process_punct(\"t. .t ¿t? ¿¿¿t???\".encode()))\n",
        "print(\"#Test  2:\", process_punct(\"\".encode()))\n",
        "print(\"#Test  3:\", process_punct(\"...t...\".encode()))\n",
        "print(\"#Test  4:\", process_punct(\"???...!!!\".encode()))\n",
        "print(\"#Test  5:\", process_punct('\"¿Cómo?\"'.encode()))\n",
        "print(\"#Test  6:\", process_punct('(--8:)'.encode()))\n",
        "print(\"#Test  7:\", process_punct('electro-quimico'.encode()))\n",
        "print(\"#Test  8:\", process_punct('que--'.encode()))\n",
        "print(\"#Test  9:\", process_punct('-ivanov'.encode()))\n",
        "print(\"#Test 10:\", process_punct('10.000, 5:45'.encode()))\n",
        "print(\"#Test 11:\", process_punct('8:00 8:00h'.encode()))\n",
        "print(\"#Test 12:\", process_punct('.¿ -¿'.encode()))\n",
        "print(\"#Test 13:\", process_punct('{y:bi}\"vamos\"'.encode()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#Test  0: t .  -t\n",
            "#Test  1: t .   . t ¿ t ? ¿ ¿ ¿ t ? ? ?\n",
            "#Test  2: \n",
            "#Test  3:  .  .  . t .  .  . \n",
            "#Test  4:  ? ? ? .  .  .  ! ! !\n",
            "#Test  5: ¿ cómo ?\n",
            "#Test  6: (--8:)\n",
            "#Test  7: electro-quimico\n",
            "#Test  8: que--\n",
            "#Test  9: ivanov\n",
            "#Test 10: 10 . 000 5:45\n",
            "#Test 11: 8:00 8:00h\n",
            "#Test 12:  . ¿  -¿ \n",
            "#Test 13: {y:bi}vamos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0S8jmQhWo3e"
      },
      "source": [
        "# Default word tokens\n",
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.trimmed = False\n",
        "        self.word2index = {\"UNK\": UNK_token}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3  # Count SOS, EOS, PAD\n",
        "\n",
        "    def addSentence(self, spl_sent):\n",
        "        for word in spl_sent:\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    # Remove words below a certain count threshold\n",
        "    def trim(self, min_count):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "\n",
        "        keep_words = []\n",
        "\n",
        "        for k, v in self.word2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_words.append(k)\n",
        "\n",
        "        print(f\"keep_words {len(keep_words)} / { len(self.word2index)} = \"\n",
        "              f\"{len(keep_words) / len(self.word2index):.4f}\")\n",
        "\n",
        "        # Reinitialize dictionaries\n",
        "        self.word2index = {\"UNK\": UNK_token}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\", UNK_token:\"UNK\"}\n",
        "        self.num_words = 4 # Count default tokens\n",
        "\n",
        "        for word in keep_words:\n",
        "            self.addWord(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DDb_teXWo6v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "f64aa12b-ce01-4287-b6ea-06c39a4ad77b"
      },
      "source": [
        "# %%time\n",
        "#TODO: multicpu\n",
        "\n",
        "voc = Voc(corpus_name)\n",
        "\n",
        "hist = []  \n",
        "for i, s in loadLines(corpus,LINES_USED):\n",
        "    s_l = len(s)\n",
        "    hist.append(s_l)\n",
        "    voc.addSentence(s)\n",
        "    \n",
        "print(f'NUmero de palabras: {voc.num_words}')\n",
        "\n",
        "arr = np.array(hist)\n",
        "plt.hist(arr, bins='auto')  # arguments are passed to np.histogram\n",
        "plt.title(f\"Sentence lenght. Capped to {MAX_LENGTH}\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "hist=[]\n",
        "for i,n in enumerate(voc.word2count):\n",
        "    c = voc.word2count[n]\n",
        "    if c>=3:\n",
        "        hist.append(c)\n",
        "        \n",
        "arr = np.array(hist)\n",
        "plt.hist(arr, bins=100,range=(3,50))  # arguments are passed to np.histogram\n",
        "plt.title(f\"Word frequency. Showing only: >=3,<50\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "c = Counter(voc.word2count)\n",
        "c.most_common()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Check de la puntuacion\n",
        "import string \n",
        "print(string.punctuation)\n",
        "\n",
        "punt_dict = {}\n",
        "for word in c:\n",
        "    for punt in string.punctuation:#\",.¿?¡!\\\":()-{}\":\n",
        "        if punt in word:\n",
        "            if len(word)>1 and c[word]>MIN_COUNT:\n",
        "                punt_dict[word] = c[word]\n",
        "c2 = Counter(punt_dict)\n",
        "c2.most_common()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "voc.trim(MIN_COUNT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NUmero de palabras: 6472\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "keep_words 402 / 6470 = 0.0621\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFF-_7fcWo9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5603a38f-a48e-46b9-ec3a-bf19f26b2825"
      },
      "source": [
        "def has_trimmed_or_unk(spl_snt):\n",
        "    \"\"\" Filter out sentences with trimmed words or words not in the voc\n",
        "    spl_snt is a list of words\"\"\"\n",
        "    for word in spl_snt:\n",
        "        if word not in voc.word2index:\n",
        "            return True\n",
        "\n",
        "trm_unk = 0\n",
        "for i,s in loadLines(corpus,LINES_USED):\n",
        "    if has_trimmed_or_unk(s): trm_unk +=1\n",
        "        \n",
        "full_pairs =  LINES_USED - trm_unk      \n",
        "\n",
        "print(f\"From {LINES_USED} pairs, {full_pairs} does not contain trimmed or unkonwn words,\", \n",
        "      f\"{full_pairs / LINES_USED:.4f} of total\")\n",
        "\n",
        "\n",
        "#aumentando min_count de 3 a 5 el vocabulario pasa de 72510(57%) a 36642(29%), sin embargo las frases aceptadas \n",
        "#solo baja un 6%, de 97.33% a 91.27%, o lo que es más impactante, con un tercio del vocabulario total podemos \n",
        "#recrear más del 90% del dataset , TODO restestear con diferentes min count cuando este el multicpu\n",
        "\n",
        "\n",
        "# spl_snt is a list of words\n",
        "def indexesFromSentence(spl_snt, voc):\n",
        "    idxs = []\n",
        "    for word in spl_snt:\n",
        "        try:\n",
        "            idxs += [voc.word2index[word]]\n",
        "        except:\n",
        "            idxs += [UNK_token] #word2index[\"UNK\"]=UNK_token\n",
        "    return idxs + [EOS_token]\n",
        "\n",
        "def gen_pairs(how_many, voc):\n",
        "    first_inp = True\n",
        "    n=0\n",
        "    for out_idx, out_snt in loadLines(corpus,LINES_USED):\n",
        "        \n",
        "        if first_inp: #first cycle, set first input\n",
        "            inp_idx, inp_snt = out_idx, out_snt\n",
        "            first_inp = False\n",
        "            continue\n",
        "\n",
        "        if inp_idx+1 == out_idx: #frases contiguas (loadLines filter long sentences)\n",
        "            ok_inp = True if WITH_UNK else not has_trimmed_or_unk(inp_snt) # if WITH_UNK==True, every inp is accepted\n",
        "            ok_out = not has_trimmed_or_unk(out_snt)\n",
        "            \n",
        "            if ok_inp and ok_out: #every word is in Voc\n",
        "                n+=1\n",
        "                yield [indexesFromSentence(inp_snt, voc),indexesFromSentence(out_snt, voc)]\n",
        "        \n",
        "        if n==how_many:break\n",
        "        inp_idx, inp_snt = out_idx, out_snt #prepare next cycle\n",
        "        \n",
        "for pair in gen_pairs(10,voc): print(pair)\n",
        "\n",
        "\n",
        "#check finales paris\n",
        "for pair in gen_pairs(10,voc): \n",
        "    for i in pair:\n",
        "        snt = []\n",
        "        for idx in i:\n",
        "            snt += [voc.index2word[idx]]\n",
        "        print(*snt)\n",
        "    print(\"---\")\n",
        "\n",
        "\n",
        "pairs = list(gen_pairs(LINES_USED,voc))\n",
        "\n",
        "\"\"\"\n",
        "se obtienen menos pares que lineas usadas, con lineas usadas se crea el diccionario, con ese diccionario elegimos \n",
        "las palabras con las que quedarnos, se descartan las lineas con palabras borradas y de ahi solo cogemos los pares\n",
        "de lineas contiguos\n",
        "\"\"\"\n",
        "len(pairs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From 5000 pairs, 939 does not contain trimmed or unkonwn words, 0.1878 of total\n",
            "[[24, 25, 3, 26, 3, 27, 3, 3, 28, 2], [19, 7, 2]]\n",
            "[[67, 53, 3, 3, 68, 62, 3, 3, 43, 60, 69, 3, 7, 2], [24, 70, 71, 72, 28, 2]]\n",
            "[[27, 3, 10, 74, 75, 8, 76, 3, 73, 26, 77, 78, 7, 2], [79, 80, 81, 82, 78, 7, 7, 7, 2]]\n",
            "[[3, 12, 3, 26, 3, 10, 3, 3, 7, 2], [95, 7, 2]]\n",
            "[[19, 102, 3, 103, 10, 30, 12, 3, 7, 2], [104, 56, 38, 7, 2]]\n",
            "[[120, 19, 35, 3, 56, 131, 3, 7, 7, 7, 133, 19, 12, 132, 76, 3, 5, 3, 7, 2], [59, 134, 43, 120, 131, 7, 2]]\n",
            "[[59, 134, 43, 120, 131, 7, 2], [39, 135, 136, 7, 2]]\n",
            "[[74, 131, 100, 3, 10, 3, 137, 3, 10, 138, 3, 19, 27, 8, 10, 3, 139, 7, 2], [140, 141, 7, 2]]\n",
            "[[24, 106, 3, 3, 97, 28, 2], [35, 58, 7, 2]]\n",
            "[[59, 3, 3, 119, 8, 3, 7, 2], [24, 146, 147, 33, 148, 28, 2]]\n",
            "¿ le UNK el UNK a UNK UNK ? EOS\n",
            "no . EOS\n",
            "---\n",
            "tan solo UNK UNK mío y UNK UNK por ella cuando UNK . EOS\n",
            "¿ les parece bien ? EOS\n",
            "---\n",
            "a UNK de ese momento los tres UNK todo el tiempo juntos . EOS\n",
            "durante todos nuestros años juntos . . . EOS\n",
            "---\n",
            "UNK que UNK el UNK de UNK UNK . EOS\n",
            "sí . EOS\n",
            "---\n",
            "no puedo UNK nada de lo que UNK . EOS\n",
            "eres un idiota . EOS\n",
            "---\n",
            "este no es UNK un camino UNK . . . si no que hay tres UNK para UNK . EOS\n",
            "yo iré por este camino . EOS\n",
            "---\n",
            "yo iré por este camino . EOS\n",
            "ey chi ho . EOS\n",
            "---\n",
            "ese camino te UNK de UNK al UNK de tu UNK no a los de UNK mujeres . EOS\n",
            "oh mierda . EOS\n",
            "---\n",
            "¿ pero UNK UNK ahora ? EOS\n",
            "es verdad . EOS\n",
            "---\n",
            "yo UNK UNK hasta los UNK . EOS\n",
            "¿ cómo puedes estar seguro ? EOS\n",
            "---\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "934"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8_KywrJWpAk"
      },
      "source": [
        "#Guardar pairs y voc\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "    \n",
        "with open(save_dir + '/pairs.pkl', 'wb') as file:\n",
        "    pickle.dump(pairs, file)\n",
        "\n",
        "with open(save_dir + '/voc.pkl', 'wb') as file:\n",
        "    voc.__module__ = \"Voc\"\n",
        "    pickle.dump(voc, file)\n",
        "\n",
        "\n",
        "# # Example for validation of the code\n",
        "# small_batch_size = 6\n",
        "# pairs_list = [random.choice(pairs) for _ in range(small_batch_size)]\n",
        "# batches = batch2TrainData(pairs_list)\n",
        "# input_variable, lengths, target_variable, mask, max_target_len = batches\n",
        "\n",
        "# print(\"input_variable:\\n\", input_variable)\n",
        "# print(\"lengths:\", lengths)\n",
        "# print(\"target_variable:\\n\", target_variable)\n",
        "# print(\"mask:\\n\", mask)\n",
        "# print(\"max_target_len:\", max_target_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX0VP0whTgPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "501a6cf1-5ec1-4b63-80ff-a5c6cc79374d"
      },
      "source": [
        "#---------------- sentencepiece ---------------------------\n",
        "! pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg10viO3YMUW"
      },
      "source": [
        "import sentencepiece as spm\n",
        "from settings import *\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdKEeyHOZViU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c652b183-a321-4eb0-f8eb-1f0890f872ed"
      },
      "source": [
        "def load_lines(how_many):\n",
        "    n = 0\n",
        "    with open(corpus, 'rb') as readfl:\n",
        "        for i, line in enumerate(readfl):\n",
        "            if max(line.find(b\"[\"),line.find(b\"]\")) == -1: #filtra los comentarios\n",
        "                n+=1\n",
        "                line = line.lstrip(b\"- \").decode()\n",
        "                yield i,line\n",
        "                if n==total_lines: break\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "    \n",
        "total_lines=500_000\n",
        "\n",
        "with open(f\"{save_dir}/writefile.txt\", 'w') as writefl:\n",
        "    for i,line in load_lines(total_lines):\n",
        "        writefl.write(line)\n",
        "\n",
        "\n",
        "cmd = (f'--input={save_dir}/writefile.txt --vocab_size=15000 --model_prefix=m_bpe --model_type=bpe '\n",
        "       f'--pad_id={PAD_token} --unk_id={UNK_token} --bos_id={SOS_token} --eos_id={EOS_token} --pad_piece=[PAD] '\n",
        "       f'--unk_piece=[UNK] --bos_piece=[SOS] --eos_piece=[EOS] --normalization_rule_name=nfkc_cf')\n",
        "\n",
        "spm.SentencePieceTrainer.train(cmd)\n",
        "os.rename('./m_bpe.vocab',f'{save_dir}/m_bpe.vocab')\n",
        "os.rename('./m_bpe.model',f'{save_dir}/m_bpe.model')\n",
        "\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(f'{save_dir}/m_bpe.model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD29nGvIZVlb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ccddd80-b8a6-427e-8eee-6cc512808424"
      },
      "source": [
        "for id in range(4):\n",
        "    print(sp.id_to_piece(id), sp.is_control(id))\n",
        "\n",
        "print('bos=', sp.bos_id(),', eos=', sp.eos_id(),', unk=', sp.unk_id(),', pad=', sp.pad_id())\n",
        "\n",
        "# print(sp.encode_as_ids('Hello world'))\n",
        "# print([sp.bos_id()] + sp.encode_as_ids('H O L A world') + [sp.eos_id()])\n",
        "\n",
        "# print(sp.encode_as_pieces('Hello world'))\n",
        "# print(sp.encode_as_pieces('HOLA Hola hola mundo estás')) \n",
        "# print([sp.bos_id()] + sp.encode_as_ids('Hola mundo estás') + [sp.eos_id()])\n",
        "\n",
        "\n",
        "def gen_pairs(how_many): #how many loaded line, pairs will be less\n",
        "    prev_ln = None\n",
        "    for i, line in load_lines(how_many):\n",
        "        if prev_ln == None: \n",
        "            prev_ln = sp.encode_as_ids(line.strip()) + [EOS_token]\n",
        "            prev_idx= i\n",
        "            continue\n",
        "        \n",
        "        line = sp.encode_as_ids(line.strip()) + [EOS_token]\n",
        "        if prev_idx+1 == i:\n",
        "            yield [prev_ln,line]\n",
        "\n",
        "        if i == how_many: break\n",
        "        prev_ln = line\n",
        "        prev_idx= i\n",
        "\n",
        "\n",
        "# for pair in gen_pairs(100):\n",
        "#     print(pair[0],sp.encode_as_pieces(sp.decode_ids(pair[0])),sp.decode_ids(pair[0]),sep=\"\\n\")\n",
        "#     print(pair[1],sp.encode_as_pieces(sp.decode_ids(pair[1])),sp.decode_ids(pair[1]),sep=\"\\n\")\n",
        "#     print()\n",
        "\n",
        "\n",
        "pairs = list(gen_pairs(LINES_USED))\n",
        "\n",
        "\n",
        "with open(save_dir + '/sp_pairs.pkl', 'wb') as file:\n",
        "    pickle.dump(pairs, file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PAD] True\n",
            "[SOS] True\n",
            "[EOS] True\n",
            "[UNK] False\n",
            "bos= 1 , eos= 2 , unk= 3 , pad= 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InEGR9QjZVo5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuiKv4DpZ64f"
      },
      "source": [
        "## Definimos el Modelo (Seq2Seq)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKjYOSITZVsV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c37451-a32d-4b17-afd6-2a4383f640ed"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pickle, random, itertools, os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pre_processing import Voc\n",
        "from settings import *\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"device = \", device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device =  cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk2t6s2za8qs"
      },
      "source": [
        "### Loading data and batching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bDsSN2ZYMab"
      },
      "source": [
        "with open(save_dir + '/voc.pkl',  'rb') as f:\n",
        "    voc   = pickle.load(f)\n",
        "    \n",
        "with open(save_dir + '/pairs.pkl','rb') as f:\n",
        "    pairs = pickle.load(f)\n",
        "    \n",
        "##with open(\"./data/loss_log.pkl\", 'rb') as f:\n",
        "##    loss_log = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88weMEjoYMdR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a4a0d5e-8072-4547-fff1-eeb2db1fca2b"
      },
      "source": [
        "def zeroPadding(l, fillvalue=PAD_token):\n",
        "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
        "\n",
        "def binaryMatrix(l, value=PAD_token):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "        m.append([])\n",
        "        for token in seq:\n",
        "            if token == PAD_token:\n",
        "                m[i].append(0)\n",
        "            else:\n",
        "                m[i].append(1)\n",
        "    return m\n",
        "\n",
        "# Returns padded input sequence tensor and lengths\n",
        "def inputVar(indexes_batch):\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, lengths\n",
        "\n",
        "# Returns padded target sequence tensor, padding mask, and max target length\n",
        "def outputVar(indexes_batch):\n",
        "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    mask = binaryMatrix(padList)\n",
        "    mask = torch.ByteTensor(mask)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, mask, max_target_len\n",
        "\n",
        "# Returns all items for a given batch of pairs\n",
        "def batch2TrainData(pair_batch):\n",
        "    pair_batch.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "    input_batch, output_batch = [], []\n",
        "    for pair in pair_batch:\n",
        "        input_batch.append(pair[0])\n",
        "        output_batch.append(pair[1])\n",
        "    inp, lengths = inputVar(input_batch)\n",
        "    output, mask, max_target_len = outputVar(output_batch)\n",
        "    return inp, lengths, output, mask, max_target_len\n",
        "\n",
        "\n",
        "# Example for validation\n",
        "small_batch_size = 6\n",
        "pairs_list = [random.choice(pairs) for _ in range(small_batch_size)]\n",
        "batches = batch2TrainData(pairs_list)\n",
        "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
        "\n",
        "print(\"input_variable:\\n\", input_variable)\n",
        "print(\"lengths:\", lengths)\n",
        "print(\"target_variable:\\n\", target_variable)\n",
        "print(\"mask:\\n\", mask)\n",
        "print(\"max_target_len:\", max_target_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_variable:\n",
            " tensor([[ 21, 307,  24,  24, 106,   3],\n",
            "        [ 74,   3,  41, 104,  19,   3],\n",
            "        [ 75,  10,   3,   3,   3,   7],\n",
            "        [133,  30,   5,  48,  34,   2],\n",
            "        [100,  12,   6,  41,   7,   0],\n",
            "        [  3, 132,   3,  28,   2,   0],\n",
            "        [255, 128,  28,   2,   0,   0],\n",
            "        [101,  62,   2,   0,   0,   0],\n",
            "        [ 12, 128,   0,   0,   0,   0],\n",
            "        [  3,   7,   0,   0,   0,   0],\n",
            "        [ 66,   2,   0,   0,   0,   0],\n",
            "        [  7,   0,   0,   0,   0,   0],\n",
            "        [  2,   0,   0,   0,   0,   0]])\n",
            "lengths: tensor([13, 11,  8,  7,  6,  4])\n",
            "target_variable:\n",
            " tensor([[ 19, 168, 180,  72, 200,  30],\n",
            "        [ 84, 300, 152,   7,  12, 185],\n",
            "        [ 12,   7,  69,   2,  19,   7],\n",
            "        [ 35,   2, 116,   0,   7,   2],\n",
            "        [128,   0,  78,   0,   2,   0],\n",
            "        [106,   0,   7,   0,   0,   0],\n",
            "        [ 19,   0,   2,   0,   0,   0],\n",
            "        [ 30,   0,   0,   0,   0,   0],\n",
            "        [185,   0,   0,   0,   0,   0],\n",
            "        [  7,   0,   0,   0,   0,   0],\n",
            "        [  2,   0,   0,   0,   0,   0]])\n",
            "mask:\n",
            " tensor([[1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 0, 1, 1],\n",
            "        [1, 0, 1, 0, 1, 0],\n",
            "        [1, 0, 1, 0, 0, 0],\n",
            "        [1, 0, 1, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0]], dtype=torch.uint8)\n",
            "max_target_len: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs5I0xoobK2d"
      },
      "source": [
        "### Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjxb8MkLT0vz"
      },
      "source": [
        "Usando el mejor mecanismo de Atención se construye un ChatBot para español usando los datos de open subtitles como sugiere el autor de este Blog: https://mc.ai/como-hacer-un-chatbot-en-espanol-y-que-te-trolee-en-el-intento/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bADaCFJEN6Pp"
      },
      "source": [
        "# Modelo de atención: Soft-Attention\n",
        "class Soft_Attention(torch.nn.Module):\n",
        "    #def __init__(self, encoder_dim, decoder_dim):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Soft_Attention, self).__init__()\n",
        "        #super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size \n",
        "        self.w_a = torch.nn.Linear(self.hidden_size, hidden_size)\n",
        "        self.u_a = torch.nn.Linear(self.hidden_size, hidden_size)\n",
        "        self.v_a = torch.nn.Linear(self.hidden_size, 1, bias = False)\n",
        "        self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "        \n",
        "    #def forward(self, encoder_state_vectors, query_vector):\n",
        "    def forward(self, query_vector, encoder_state_vectors):\n",
        "\n",
        "        query_vector2 = query_vector.permute(1,0, 2)\n",
        "        encoder_state_vectors2 = encoder_state_vectors.permute(1,0, 2)\n",
        "\n",
        "        batch_size, num_vectors, vector_size = encoder_state_vectors2.size()\n",
        "\n",
        "        vector_energy = torch.tanh(self.w_a(query_vector2.view(batch_size, 1, vector_size)) + self.u_a(encoder_state_vectors2) ) \n",
        "        vector_scores = self.v_a(vector_energy)\n",
        "        vector_probabilities = F.softmax(vector_scores, dim=1)\n",
        "\n",
        "        ##weighted_vectors = encoder_state_vectors2 * vector_probabilities.view(batch_size, num_vectors, 1)\n",
        "        #context_vectors = torch.sum(weighted_vectors, dim=1)\n",
        "        ##context_vectors = torch.sum(weighted_vectors, dim=2).unsqueeze(1)\n",
        "        \n",
        "        #return context_vectors, vector_probabilities, vector_scores\n",
        "        #return context_vectors #.permute(2,1, 0) #(1,2, 0)\n",
        "        return vector_probabilities.permute(0,2, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kazRkcX5bME4"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "\n",
        "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
        "        #   because our input size is a word embedding with number of features == hidden_size\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        # Convert word indexes to embeddings\n",
        "        embedded = self.embedding(input_seq)\n",
        "        # Pack padded batch of sequences for RNN module\n",
        "        #packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths).to(device)\n",
        "\n",
        "        # Forward pass through GRU\n",
        "        self.gru.flatten_parameters()\n",
        "        outputs, hidden = self.gru(embedded, hidden)\n",
        "        #outputs, hidden = self.gru(packed, hidden)\n",
        "\n",
        "        # Unpack padding\n",
        "        #outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "        # Sum bidirectional GRU outputs\n",
        "        #outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
        "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
        "\n",
        "        # Return output and final hidden state\n",
        "        return outputs, hidden\n",
        "\n",
        "# Luong attention layer\n",
        "class Attn(torch.nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.method = method\n",
        "\n",
        "        if self.method not in ['dot', 'general', 'concat']:\n",
        "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
        "        self.hidden_size = hidden_size\n",
        "        if self.method == 'general':\n",
        "            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
        "        elif self.method == 'concat':\n",
        "            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "    def dot_score(self, hidden, encoder_output):\n",
        "        return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "    def general_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(encoder_output)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "    def concat_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "        return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        \n",
        "        # Calculate the attention weights (energies) based on the given method\n",
        "        if self.method == 'general':\n",
        "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'concat':\n",
        "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'dot':\n",
        "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "        # Transpose max_length and batch_size dimensions\n",
        "        attn_energies = attn_energies.t()\n",
        "\n",
        "        # Return the softmax normalized probability scores (with added dimension)\n",
        "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
        "\n",
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1,tie_weights=False):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Keep for reference\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        #self.attn = Attn(attn_model, hidden_size)\n",
        "        self.attn = Soft_Attention(attn_model, hidden_size)\n",
        "        \n",
        "        if tie_weights:\n",
        "            self.out.weight = self.embedding.weight\n",
        "\n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "\n",
        "        # Note: we run this one step (word) at a time\n",
        "        # Get embedding of current input word\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "        # Forward through unidirectional GRU\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "        # Calculate attention weights from the current GRU output\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "        # Predict next word using Luong eq. 6\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        # Return output and final hidden state\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "def maskNLLLoss(inp, target, mask):\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
        "    loss = crossEntropy.masked_select(mask).mean()\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brJ13J1Fbhe9"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMTy3THabOp0"
      },
      "source": [
        "def plot_loss(d):\n",
        "    x,y=[],[]\n",
        "    for k,v in d.items():\n",
        "            x.append(k)\n",
        "            y.append(v)\n",
        "    plt.plot(x,y)\n",
        "\n",
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
        "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
        "\n",
        "    # Zero gradients\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Set device options\n",
        "    input_variable = input_variable.to(device)\n",
        "    lengths = lengths.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "\n",
        "    # Initialize variables\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "    # Forward pass through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "\n",
        "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
        "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # Set initial decoder hidden state to the encoder's final hidden state\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    # Determine if we are using teacher forcing this iteration\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    # Forward batch of sequences through decoder one time step at a time\n",
        "    if use_teacher_forcing:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # Teacher forcing: next input is current target\n",
        "            decoder_input = target_variable[t].view(1, -1)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # No teacher forcing: next input is decoder's own current output\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    # Perform backpropatation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip gradients: gradients are modified in place\n",
        "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "    # Adjust model weights\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return sum(print_losses) / n_totals\n",
        "\n",
        "\n",
        "def trainIters(voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, \n",
        "               encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, \n",
        "               clip, corpus_name, loadFilename, total_iter):\n",
        "\n",
        "    # Load batches for each iteration\n",
        "    #TODO: generator form to save memory of training_batches\n",
        "    training_batches = [batch2TrainData([random.choice(pairs) for _ in range(batch_size)])\n",
        "                      for _ in range(n_iteration)]\n",
        "\n",
        "    # Initializations\n",
        "#     print('Initializing ...')\n",
        "    start_iteration = 0\n",
        "    print_loss = 0\n",
        "    if loadFilename:\n",
        "        start_iteration = checkpoint['iteration']\n",
        "\n",
        "    # Training loop\n",
        "#     print(\"Training...\")\n",
        "    for iteration in range(1,n_iteration+1):\n",
        "        training_batch = training_batches[iteration-1]\n",
        "        # Extract fields from batch\n",
        "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
        "\n",
        "        # Run a training iteration with batch\n",
        "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
        "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
        "\n",
        "        print_loss += loss\n",
        "        \n",
        "        # Print progress\n",
        "        if iteration % print_every == 0:\n",
        "            print_loss_avg = print_loss / print_every\n",
        "            assert np.isnan(print_loss_avg) == False\n",
        "            loss_dict[total_iter+iteration] = print_loss_avg\n",
        "            print(f\"Iteration: {iteration}; Percent complete: {iteration / n_iteration * 100:.1f}%; \"\n",
        "                  f\"Average loss: {print_loss_avg:.4f}\")\n",
        "            print_loss = 0\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (iteration % save_every == 0):\n",
        "            directory = os.path.join(save_dir, \"checkpoints\")\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            torch.save({\n",
        "                'iteration': start_iteration+iteration,\n",
        "                'en': encoder.state_dict(),\n",
        "                'de': decoder.state_dict(),\n",
        "                'en_opt': encoder_optimizer.state_dict(),\n",
        "                'de_opt': decoder_optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                'voc_dict': voc.__dict__,\n",
        "                'embedding': embedding.state_dict(),\n",
        "                \"total_iter\": total_iter+iteration,\n",
        "                'loss': loss_dict #for plotting\n",
        "            }, os.path.join(directory, f'{start_iteration+iteration}_checkpoint.tar'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXTgXulBbOtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e8bfe3c-85e3-4195-a804-4b4a8d485934"
      },
      "source": [
        "# Configure models\n",
        "attn_model = 'dot'\n",
        "#attn_model = 'general'\n",
        "#attn_model = 'concat'\n",
        "hidden_size = 500 #tamaño del embedding y del hidden, tienen que ser iguales para el output embedding\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 128\n",
        "\n",
        "# Set checkpoint to load from; set to None if starting from scratch\n",
        "train_from_zero = True\n",
        "load_last_iter  = False\n",
        "chkpt_dir = os.path.join(save_dir, \"checkpoints\")\n",
        "\n",
        "if train_from_zero:\n",
        "    loadFilename = None\n",
        "    total_iter = 0\n",
        "    loss_dict = {}\n",
        "else:\n",
        "    if load_last_iter: #load last save\n",
        "        chkpt = os.listdir(chkpt_dir)[-1]\n",
        "        loadFilename = os.path.join(chkpt_dir,chkpt)\n",
        "    else:    \n",
        "        checkpoint_iter = 20_000 #load especific iter\n",
        "        loadFilename = os.path.join(chkpt_dir, f'{checkpoint_iter}_checkpoint.tar')\n",
        "\n",
        "print('Building encoder and decoder ...')\n",
        "# Initialize word embeddings\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "\n",
        "# Initialize encoder & decoder models\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout,True)\n",
        "print(\"Nº of params: \", count_parameters(encoder) + count_parameters(decoder))\n",
        "\n",
        "# Use appropriate device\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "\n",
        "# Load model if a loadFilename is provided\n",
        "if loadFilename:\n",
        "    # If loading on same machine the model was trained on\n",
        "    checkpoint = torch.load(loadFilename)\n",
        "    # If loading a model trained on GPU to CPU\n",
        "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))+\n",
        "    encoder.load_state_dict(checkpoint['en'])\n",
        "    decoder.load_state_dict(checkpoint['de'])\n",
        "    embedding.load_state_dict(checkpoint['embedding'])\n",
        "    voc.__dict__ = checkpoint['voc_dict']\n",
        "    total_iter = checkpoint[\"total_iter\"]\n",
        "    loss_dict = checkpoint[\"loss\"]\n",
        "    \n",
        "print('Models built and ready to go!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Nº of params:  11926906\n",
            "Models built and ready to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeGRwGn1b6xw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44abb55b-a0a2-4f50-a54b-7d101fd528a6"
      },
      "source": [
        "# Configure training/optimization\n",
        "clip = 50.0\n",
        "teacher_forcing_ratio = 1\n",
        "learning_rate = 4e-5\n",
        "decoder_learning_ratio = 5.0\n",
        "n_iteration = 2_000 #10_000\n",
        "print_every = 1_000\n",
        "#save_every = 11_000\n",
        "save_every = 1_000\n",
        "wd = 1e-5\n",
        "\n",
        "# Initialize optimizers\n",
        "print('Building optimizers ...')\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate,weight_decay=wd)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio,weight_decay=wd)\n",
        "if loadFilename:\n",
        "    encoder_optimizer.load_state_dict(checkpoint['en_opt'])\n",
        "    decoder_optimizer.load_state_dict(checkpoint['de_opt'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building optimizers ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yYM8ONWb61c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "cf9b9afd-af75-41c3-c95d-fa78511e6089"
      },
      "source": [
        "%%time\n",
        "# Ensure dropout layers are in train mode\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "loss_log = {}\n",
        "# Run training iterations\n",
        "for _ in range(1):\n",
        "    print(f\"No. iterations: {total_iter}\")\n",
        "    trainIters(voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "               embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
        "               print_every, save_every, clip, corpus_name, loadFilename,total_iter)\n",
        "    total_iter+=n_iteration\n",
        "    \n",
        "    #print(\"open archivo..\")\n",
        "    with open(\"./data/loss_log.pkl\", 'wb') as f:\n",
        "        loss_log[corpus_name] = loss_dict\n",
        "        pickle.dump(loss_log, f)\n",
        "    plot_loss(loss_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. iterations: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:126: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 1000; Percent complete: 50.0%; Average loss: 0.6747\n",
            "Iteration: 2000; Percent complete: 100.0%; Average loss: 0.1002\n",
            "CPU times: user 2min 45s, sys: 46.5 s, total: 3min 32s\n",
            "Wall time: 3min 36s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7azFPIrab65Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "1c4c8315-69d8-482e-98d6-6cbd6ab93df3"
      },
      "source": [
        "loss_log['seq2seq'] = loss_log[corpus_name]\n",
        "loss_log.pop(corpus_name)\n",
        "\n",
        "#tres metodos de tratar la puntuacion, entrenado por 14 \"epochs\" con 4e4 y 2 con 4e5\n",
        "l = list(loss_log.keys())\n",
        "for k,v in loss_log.items():\n",
        "    plot_loss(v)\n",
        "    plt.gca().legend(l)\n",
        "\n",
        "#next\n",
        "#test y subir modelo?\n",
        "#guardar tiempo 10epochs y num params\n",
        "#grafico de loss escalado a tiempo, y scatter plt de loss at 10 y num of params\n",
        "#implement outputs layers\n",
        "\n",
        "#train with simple punct\n",
        "#reduce data to see how affect to training. smaller data faster training(worse generaliaztion but useful to do test runs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIN2vJoJcRWv"
      },
      "source": [
        "### Eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP41hy11bOw4"
      },
      "source": [
        "import re\n",
        "from pre_processing import process_punct, indexesFromSentence\n",
        "\n",
        "def custom_capitalize(s):\n",
        "    for i, c in enumerate(s):\n",
        "        if c.isalpha():\n",
        "            break\n",
        "    return s[:i] + s[i:].capitalize()\n",
        "\n",
        "\n",
        "def reformatString(l):\n",
        "    s = l.strip().lower()\n",
        "#     s = re.sub(r\"<guion_inic>\",r\"\", s)\n",
        "    s = re.sub(r\"\\s+([.!?])\", r\"\\1\", s)\n",
        "    s = re.sub(r\"([¡¿])\\s+\", r\"\\1\", s)\n",
        "    s = re.sub(r\"\\s+\", r\" \", s)\n",
        "    return custom_capitalize(s).strip()\n",
        "\n",
        "class GreedySearchDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(GreedySearchDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, input_seq, input_length, max_length):\n",
        "        # Forward input through encoder model\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
        "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "        # Initialize decoder input with SOS_token\n",
        "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
        "        # Initialize tensors to append decoded words to\n",
        "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
        "        all_scores = torch.zeros([0], device=device)\n",
        "        # Iteratively decode one word token at a time\n",
        "        for _ in range(max_length):\n",
        "            # Forward pass through decoder\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # Obtain most likely word token and its softmax score\n",
        "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "            # Record token and score\n",
        "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "            # Prepare current token to be next decoder input (add a dimension)\n",
        "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "        # Return collections of word tokens and scores\n",
        "        return all_tokens, all_scores\n",
        "\n",
        "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
        "    ### Format input sentence as a batch\n",
        "    # words -> indexes\n",
        "    sentence = sentence.split()\n",
        "    indexes_batch = [indexesFromSentence(sentence, voc)]\n",
        "    # Create lengths tensor\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    # Transpose dimensions of batch to match models' expectations\n",
        "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
        "    # Use appropriate device\n",
        "    input_batch = input_batch.to(device)\n",
        "    lengths = lengths.to(device)\n",
        "    # Decode sentence with searcher\n",
        "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
        "    # indexes -> words\n",
        "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
        "    return decoded_words\n",
        "\n",
        "\n",
        "def evaluateInput(encoder, decoder, searcher, voc):\n",
        "    input_sentence = ''\n",
        "    while(1):\n",
        "        try:\n",
        "            # Get input sentence\n",
        "            input_sentence = input('> ')\n",
        "            # Check if it is quit case\n",
        "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
        "            # Normalize sentence\n",
        "#             input_sentence = \"-\"+input_sentence #para que siga el formato de guiones de una conversacion\n",
        "            input_sentence = process_punct(input_sentence.encode())\n",
        "            # Evaluate sentence\n",
        "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
        "            # Format and print response sentence\n",
        "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "            raw_ans = ' '.join(output_words)\n",
        "            ans = reformatString(raw_ans)\n",
        "            print('Bot:',ans)\n",
        "\n",
        "        except KeyError:\n",
        "            print(\"Error: Encountered unknown word.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRMFm2c4cTdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4262882-463e-4db9-e889-2cc729edd787"
      },
      "source": [
        "# Set dropout layers to eval mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "# Initialize search module\n",
        "searcher = GreedySearchDecoder(encoder, decoder)\n",
        "\n",
        "# Begin chatting (uncomment and run the following line to begin)\n",
        "evaluateInput(encoder, decoder, searcher, voc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> hola\n",
            "Bot: Hola....................\n",
            "> que tal\n",
            "Bot: De acuerdo...................\n",
            "> como esta todo\n",
            "Bot: ¿Qué? sargento cutter? guau...............\n",
            "> yo no soy\n",
            "Bot: Ahí está...................\n",
            "> y tu?\n",
            "Bot: Vamos....................\n",
            "> a donde?\n",
            "Bot: Cutter....................\n",
            "> ya es viernes\n",
            "Bot: Sí....................\n",
            "> la noche esta tranquila\n",
            "Bot: ¿Para qué??................\n",
            "> para dormir\n",
            "Bot: Gracias sahib................\n",
            "> quien eres?\n",
            "Bot: Y eso es todo..................\n",
            "> me caes mal\n",
            "Bot: ¡Sargento ballantine! mío.............\n",
            "> no te entiendo\n",
            "Bot: No...............\n",
            "> sabes decir algo?\n",
            "Bot: Eso es...................\n",
            "> nos vemos\n",
            "Bot: ¿Nos??................\n",
            "> tu no\n",
            "Bot: ¡En serio!.................\n",
            "> solo yo\n",
            "Bot: Ya esta...................\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJhPhXmBcTgi"
      },
      "source": [
        "### Discusión"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvR4cKeMUo7S"
      },
      "source": [
        "### Discusión\n",
        "Por cuestión de tiempo se tuvo que recortar el tamañó de los datos de entrenamiento y el número de iteracciones al entrenar. Sin embargo, el chatbot parece funcionar relativamente bien, en muchos casos no responde coherentemente, pero en preguntas sencillas con respuestas de si o no logra responder bien.\n",
        "\n",
        "Considero que el entrenamiento todavía puede mejorar bastante al considerar el corpus completo y el modelo de atención puede ayudar mucho a dar contexto a lo que se pregunta y se responde, más que el producto punto que se usaba antes como score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvYXqwNKcTmR"
      },
      "source": [
        "> hola\n",
        "Bot: Hola....................\n",
        "> que tal\n",
        "Bot: De acuerdo...................\n",
        "> como esta todo\n",
        "Bot: ¿Qué? sargento cutter? guau...............\n",
        "> yo no soy\n",
        "Bot: Ahí está...................\n",
        "> y tu?\n",
        "Bot: Vamos....................\n",
        "> a donde?\n",
        "Bot: Cutter....................\n",
        "> ya es viernes\n",
        "Bot: Sí....................\n",
        "> la noche esta tranquila\n",
        "Bot: ¿Para qué??................\n",
        "> para dormir\n",
        "Bot: Gracias sahib................\n",
        "> quien eres?\n",
        "Bot: Y eso es todo..................\n",
        "> me caes mal\n",
        "Bot: ¡Sargento ballantine! mío.............\n",
        "> no te entiendo\n",
        "Bot: No...............\n",
        "> sabes decir algo?\n",
        "Bot: Eso es...................\n",
        "> nos vemos\n",
        "Bot: ¿Nos??................\n",
        "> tu no\n",
        "Bot: ¡En serio!.................\n",
        "> solo yo\n",
        "Bot: Ya esta..................."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oQX-JzGcTrY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sywPEd6cTkI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}